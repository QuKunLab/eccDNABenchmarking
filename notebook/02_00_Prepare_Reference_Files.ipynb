{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff77bf4f-48c1-44fe-b265-8f582e65aa88",
   "metadata": {},
   "source": [
    "## Section2 Part0 Generate Reference Files\n",
    "#### Ke Liu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e8b915-d6de-4403-898a-47d842eddd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import subprocess as sp\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d097c8a-3f23-477f-8d6d-8e194d58dfcc",
   "metadata": {},
   "source": [
    "### 1 Generate Clean Reference Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac9b45-c419-46f6-b8e3-590ef1b11315",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_fasta = '/home/qukun/liuke/Reference/UCSC/hg38/hg38.fa'\n",
    "genome_fai = '/home/qukun/liuke/Reference/UCSC/hg38/hg38.fa.fai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a264fd2-de90-42e5-b824-3ae59b64a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract sequence information from fasta\n",
    "def get_seq(chrom, start, end, genome_fasta = genome_fasta):\n",
    "    _shell2output = '/home/qukun/liuke/miniconda3/envs/eccDNA/bin/samtools faidx {0} {1}:{2}-{3}'.format(genome_fasta, chrom, start, end)\n",
    "    out = sp.check_output(_shell2output, shell = True)\n",
    "    out = out.decode('utf-8')\n",
    "    out = out.split('\\n')\n",
    "    title = out.pop(0)\n",
    "    seq = ''.join(out).upper()\n",
    "    return seq\n",
    "\n",
    "## extract sequence of each chromosome in fasta\n",
    "def genome_weight(genome_fasta = genome_fasta):\n",
    "    '''\n",
    "    Calculate the length & weigth of each protien\n",
    "    '''\n",
    "    genome_fai = genome_fasta + '.fai'\n",
    "    genome_df = pd.read_csv(genome_fai,sep= '\\t',header=None, names = [\"name\",\"length\"], index_col = 0, usecols = range(2))\n",
    "    #Remove the unknown chr \n",
    "    genome_df = genome_df.drop(genome_df.filter(regex='_',axis=0).index)\n",
    "    genome_df['chrom'] = genome_df.index\n",
    "    genome_df['weight'] = genome_df['length']/genome_df['length'].sum()\n",
    "    genome_df['seq'] = genome_df.apply(lambda x: get_seq(x['chrom'],1,x[\"length\"]), axis=1)\n",
    "    return genome_df\n",
    "genome_df = genome_weight()\n",
    "\n",
    "## write sequence of each chromosome in fasta\n",
    "def write_fasta(genome_df,fasta):\n",
    "    with open(fasta,'w') as f:\n",
    "        for i in genome_df.index:\n",
    "            k=0\n",
    "            f.write('>{0}\\n'.format(i))\n",
    "            for j in range(int(genome_df.loc[i,'length']/50)):\n",
    "                f.write(genome_df.loc[i,'seq'][50*k:50*(k+1)])\n",
    "                k=k+1\n",
    "                f.write('\\n')\n",
    "            f.write(genome_df.loc[i,'seq'][50*k:])\n",
    "            f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "## write chr 1-22 and X sequence to a new fasta\n",
    "chr_num=list(range(1,23))+['X']\n",
    "chr_list=['{0}{1}'.format('chr',x) for x in chr_num]\n",
    "write_fasta(genome_df.loc[chr_list,:],'/home/qukun/liuke/reference/clean/hg38.clean.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd9e35-e114-4512-922d-2fb13cd3c3e4",
   "metadata": {},
   "source": [
    "### 1 Generate  RepeatMask Bed Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ece4aa-a183-4311-a351-a2f0b1f9e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1 Generate the ReapeatMask Bed Files\n",
    "def extract_repeats(repeatmasker, output_path):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    repeatmasker = pd.read_csv(repeatmasker, sep='\\t',header=None,index_col=None,skiprows=2)\n",
    "    repeat_df = pd.DataFrame(columns=['chr','start','end','repeat','class','strand','ID'])\n",
    "    repeat_df['chr'] = repeatmasker.apply(lambda x: x[0].split()[4],axis=1)\n",
    "    repeat_df['start'] = repeatmasker.apply(lambda x: x[0].split()[5],axis=1)\n",
    "    repeat_df['end'] = repeatmasker.apply(lambda x: x[0].split()[6],axis=1)\n",
    "    repeat_df['repeat'] = repeatmasker.apply(lambda x: x[0].split()[9],axis=1)\n",
    "    repeat_df['class'] = repeatmasker.apply(lambda x: x[0].split()[10],axis=1)\n",
    "    repeat_df['strand'] = repeatmasker.apply(lambda x: x[0].split()[8],axis=1)\n",
    "    repeat_df['ID'] = repeatmasker.apply(lambda x: x[0].split()[-1],axis=1)\n",
    "    ##\n",
    "    strand_dict = {'C':'-','+':'+'}\n",
    "    repeat_df['strand'] = repeat_df.apply(lambda x: strand_dict[x['strand']],axis=1)\n",
    "    ##\n",
    "    region_dict = {}\n",
    "    for region in repeat_df['class'].unique():\n",
    "        if '?' in region: \n",
    "            region_dict[region] = 'Unclear'\n",
    "        elif '/' in region:\n",
    "            region_dict[region] =region.split('/')[0]\n",
    "        else:\n",
    "            region_dict[region] = region\n",
    "    repeat_df['class'] = repeat_df.apply(lambda x: region_dict[x['class']],axis=1)\n",
    "    ##\n",
    "    for repeat in repeat_df['class'].unique():\n",
    "        repeat_df[repeat_df['class']==repeat].to_csv(join(output_path,repeat+'.bed'),sep='\\t',header=None,index=None)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c0efa-bb61-442e-b7fc-89e4027e98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hg38\n",
    "extract_repeats('/home/qukun/liuke/reference/ucsc/hg38/hg38.fa.out', '/home/qukun/liuke/reference/ucsc/hg38/repeatmask')\n",
    "sp.check_call('grep L1 /home/qukun/liuke/reference/ucsc/hg38/repeatmask/LINE.bed > /home/qukun/liuke/reference/ucsc/hg38/repeatmask/L1.bed', shell=True)\n",
    "sp.check_call('grep L2 /home/qukun/liuke/reference/ucsc/hg38/repeatmask/LINE.bed > /home/qukun/liuke/reference/ucsc/hg38/repeatmask/L2.bed', shell=True)\n",
    "sp.check_call('grep Alu /home/qukun/liuke/reference/ucsc/hg38/repeatmask/SINE.bed > /home/qukun/liuke/reference/ucsc/hg38/repeatmask/Alu.bed', shell=True)\n",
    "sp.check_call('mv /home/qukun/liuke/reference/ucsc/hg38/repeatmask/Retroposon.bed /home/qukun/liuke/reference/ucsc/hg38/repeatmask/SVA.bed', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f0aed5-ef0c-46af-883a-54fee2ec380e",
   "metadata": {},
   "source": [
    "### 2 Generate genebody Bed Files\n",
    "##### using Rscript https://github.com/saketkc/gencode_regions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a39e6ed1-f952-4831-bb8e-12a8f5145219",
   "metadata": {},
   "source": [
    "## This is run in shell\n",
    "Rscript <path_to_create_regions_from_gencode.R> <path_to_gencode.v38.annotation.gtf> <path_to_output_dir>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521dee1f-7dc5-4226-8c68-77c508bc21b1",
   "metadata": {},
   "source": [
    "### 3 Generate cpg Bed Files\n",
    "##### downloading the cpgIslandExt.txt on https://hgdownload.soe.ucsc.edu/goldenPath/hg38/database/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b9db0-07fa-458e-9fa3-39004c625fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transfer the txt files into BED files\n",
    "cpg = pd.read_csv('/home/qukun/liuke/reference/GENCODE/hg38/genebody/cpgIslandExt.txt',sep='\\t',index_col=0,header=None)\n",
    "cpg[4]=cpg[4].apply(lambda x: x.replace(' ','_'))\n",
    "cpg[[1,2,3,4]].to_csv('/home/qukun/liuke/reference/GENCODE/hg38/genebody/cpg.bed', sep='\\t', index=None, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eccDNA",
   "language": "python",
   "name": "eccdna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
